{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3703e3fc",
   "metadata": {},
   "source": [
    "# 06 - Final Pipeline \n",
    "\n",
    "Bu dok√ºman, akciƒüer kanseri risk tahmini i√ßin olu≈üturulan **production-ready Machine Learning Pipeline** mimarisini a√ßƒ±klamaktadƒ±r. Pipeline; veri temizleme, feature engineering, encoding, modelleme ve √ßƒ±ktƒ± √ºretme adƒ±mlarƒ±nƒ± mod√ºler ve yeniden kullanƒ±labilir bir bi√ßimde birle≈ütirmektedir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d16c3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c5d5416",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# YAPILANDIRMA\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "CV_FOLDS = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "322ef344",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  1. VERƒ∞ Y√úKLEME\n",
    "\n",
    "df = pd.read_csv('../data/raw/cancer-patient-data-sets.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b65dd616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Applying Feature Engineering...\n",
      "‚úÖ Feature Engineering Complete: (1000, 44)\n"
     ]
    }
   ],
   "source": [
    "# 2. √ñZELLƒ∞K M√úHENDƒ∞SLƒ∞ƒûƒ∞ FONKSƒ∞YONU\n",
    "\n",
    "def engineer_features(df):\n",
    "    \"\"\"\n",
    "    T√ºm √∂zellik m√ºhendisliƒüi d√∂n√º≈ü√ºmlerini uygulayalƒ±m.\n",
    "    \"\"\"\n",
    "    df_fe = df.copy()\n",
    "    \n",
    "    # Ya≈ü Gruplarƒ±\n",
    "    df_fe['Age_Group'] = pd.cut(\n",
    "        df_fe['Age'], \n",
    "        bins=[0, 25, 40, 55, 100], \n",
    "        labels=[0, 1, 2, 3]).astype(int)       \n",
    "    \n",
    "    # Risk Puanlarƒ±\n",
    "    df_fe['Environmental_Risk'] = (\n",
    "        df_fe['Air Pollution'] + \n",
    "        df_fe['Dust Allergy'] + \n",
    "        df_fe['OccuPational Hazards']\n",
    "    ) / 3\n",
    "    \n",
    "    df_fe['Lifestyle_Risk'] = (\n",
    "        df_fe['Smoking'] + \n",
    "        df_fe['Alcohol use'] + \n",
    "        df_fe['Obesity'] +\n",
    "        (10 - df_fe['Balanced Diet'])\n",
    "    ) / 4\n",
    "    \n",
    "    df_fe['Genetic_Health_Risk'] = (\n",
    "        df_fe['Genetic Risk'] + \n",
    "        df_fe['chronic Lung Disease']\n",
    "    ) / 2\n",
    "    \n",
    "    # Belirti puanlarƒ±\n",
    "    symptom_cols = ['Chest Pain', 'Coughing of Blood', 'Fatigue', 'Weight Loss',\n",
    "                    'Shortness of Breath', 'Wheezing', 'Swallowing Difficulty']\n",
    "    df_fe['Symptom_Severity'] = df_fe[symptom_cols].mean(axis=1)\n",
    "    \n",
    "    df_fe['Respiratory_Score'] = (\n",
    "        df_fe['Shortness of Breath'] + \n",
    "        df_fe['Wheezing'] + \n",
    "        df_fe['Dry Cough'] +\n",
    "        df_fe['chronic Lung Disease']\n",
    "    ) / 4\n",
    "    \n",
    "    # Kritik semptomlar\n",
    "    critical_threshold = 6\n",
    "    df_fe['Critical_Symptom_Count'] = (\n",
    "        (df_fe['Chest Pain'] >= critical_threshold).astype(int) +\n",
    "        (df_fe['Coughing of Blood'] >= critical_threshold).astype(int) +\n",
    "        (df_fe['Weight Loss'] >= critical_threshold).astype(int) +\n",
    "        (df_fe['Shortness of Breath'] >= critical_threshold).astype(int)\n",
    "    )\n",
    "    \n",
    "    # Genel risk\n",
    "    df_fe['Overall_Risk_Score'] = (\n",
    "        df_fe['Environmental_Risk'] * 0.25 +\n",
    "        df_fe['Lifestyle_Risk'] * 0.30 +\n",
    "        df_fe['Genetic_Health_Risk'] * 0.20 +\n",
    "        df_fe['Symptom_Severity'] * 0.25\n",
    "    )\n",
    "    \n",
    "    # Etkile≈üimler\n",
    "    df_fe['Smoking_Age_Interaction'] = df_fe['Smoking'] * df_fe['Age']\n",
    "    df_fe['Genetic_Age_Interaction'] = df_fe['Genetic Risk'] * df_fe['Age']\n",
    "    df_fe['Smoking_Pollution'] = df_fe['Smoking'] * df_fe['Air Pollution']\n",
    "    df_fe['Obesity_ChronicLung'] = df_fe['Obesity'] * df_fe['chronic Lung Disease']\n",
    "    df_fe['PassiveSmoker_Pollution'] = df_fe['Passive Smoker'] * df_fe['Air Pollution']\n",
    "    \n",
    "    # Polinom √∂zellikleri\n",
    "    for feat in ['Smoking', 'Air Pollution', 'Genetic Risk']:\n",
    "        df_fe[f'{feat}_squared'] = df_fe[feat] ** 2\n",
    "    \n",
    "    # Binning\n",
    "    df_fe['Smoking_Level'] = pd.cut(\n",
    "        df_fe['Smoking'], \n",
    "        bins=[0, 2, 5, 10], \n",
    "        labels=[0, 1, 2]).astype(int)\n",
    "    \n",
    "    df_fe['Pollution_Level'] = pd.cut(\n",
    "        df_fe['Air Pollution'], \n",
    "        bins=[0, 3, 6, 10], \n",
    "        labels=[0, 1, 2]).astype(int)\n",
    "\n",
    "    return df_fe\n",
    "\n",
    "print(\"\\nüîß Applying Feature Engineering...\")\n",
    "df_engineered = engineer_features(df)\n",
    "print(f\"‚úÖ Feature Engineering Complete: {df_engineered.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc7aeeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Final Feature Set: 28 features\n",
      "   1. Smoking\n",
      "   2. Genetic Risk\n",
      "   3. Air Pollution\n",
      "   4. Alcohol use\n",
      "   5. chronic Lung Disease\n",
      "   6. Age\n",
      "   7. Obesity\n",
      "   8. Chest Pain\n",
      "   9. Coughing of Blood\n",
      "   10. Fatigue\n",
      "   ... (showing first 10)\n",
      "\n",
      "‚úÖ X shape: (1000, 28)\n",
      "‚úÖ y distribution:\n",
      "Level\n",
      "High      365\n",
      "Medium    332\n",
      "Low       303\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 3. SON √ñZELLƒ∞K SETƒ∞ SE√áƒ∞Mƒ∞\n",
    "\n",
    "# En uygun √∂zellik setini tanƒ±mlayalƒ±m; deƒüerlendirme sonu√ßlarƒ±na g√∂re yapƒ±lƒ±r.\n",
    "# Bunlar genellikle √∂zellik √∂nem analizinden elde edilen en √∂nemli √∂zelliklerdir.\n",
    "\n",
    "FINAL_FEATURES = [\n",
    "    # Original high-importance features\n",
    "    'Smoking', 'Genetic Risk', 'Air Pollution', 'Alcohol use',\n",
    "    'chronic Lung Disease', 'Age', 'Obesity', 'Chest Pain',\n",
    "    'Coughing of Blood', 'Fatigue', 'Weight Loss', 'Shortness of Breath',\n",
    "    'Wheezing', 'Passive Smoker', 'OccuPational Hazards',\n",
    "    \n",
    "    # Engineered features\n",
    "    'Overall_Risk_Score', 'Lifestyle_Risk', 'Environmental_Risk',\n",
    "    'Symptom_Severity', 'Respiratory_Score', 'Genetic_Health_Risk',\n",
    "    'Smoking_Age_Interaction', 'Genetic_Age_Interaction',\n",
    "    'Smoking_squared', 'Air Pollution_squared', 'Critical_Symptom_Count',\n",
    "    'Age_Group', 'Smoking_Level'\n",
    "]\n",
    "\n",
    "print(f\"\\nüìù Final Feature Set: {len(FINAL_FEATURES)} features\")\n",
    "for i, feat in enumerate(FINAL_FEATURES[:10], 1):\n",
    "    print(f\"   {i}. {feat}\")\n",
    "print(\"   ... (showing first 10)\")\n",
    "\n",
    "# Prepare X and y\n",
    "X = df_engineered[FINAL_FEATURES]\n",
    "y = df_engineered['Level']\n",
    "\n",
    "print(f\"\\n‚úÖ X shape: {X.shape}\")\n",
    "print(f\"‚úÖ y distribution:\\n{y.value_counts()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67a46ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Train set: 800 samples\n",
      "‚úÖ Test set:  200 samples\n"
     ]
    }
   ],
   "source": [
    "# 4. TRAIN-TEST AYRIMI\n",
    "\n",
    "TEST_SIZE = 0.20       # Test seti i√ßin verinin %20'si\n",
    "RANDOM_STATE = 42    # Sabit bir √ßekirdek (seed) deƒüeri\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=TEST_SIZE, \n",
    "    random_state=RANDOM_STATE, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Train set: {X_train.shape[0]} samples\")\n",
    "print(f\"‚úÖ Test set:  {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64dab1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ StandardScaler fitted and applied\n"
     ]
    }
   ],
   "source": [
    "# 5. √ñN ƒ∞≈ûLEME\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"‚úÖ StandardScaler fitted and applied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7c24e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Model: RandomForestClassifier\n",
      "‚öôÔ∏è Parameters:\n",
      "   - n_estimators: 300\n",
      "   - max_depth: 15\n",
      "   - min_samples_split: 2\n",
      "   - min_samples_leaf: 1\n",
      "\n",
      "üöÄ Training final model...\n",
      "‚úÖ Training completed!\n"
     ]
    }
   ],
   "source": [
    "# 6. MODEL Eƒûƒ∞Tƒ∞Mƒ∞ (SON MODEL)\n",
    "# En iyi model yapƒ±landƒ±rmasƒ± yaparak  optimizasyon sonu√ßlarƒ±na g√∂re ayarlayalƒ±m.\n",
    "\n",
    "final_model = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=15,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f\"\\nüîß Model: {final_model.__class__.__name__}\")\n",
    "print(\"‚öôÔ∏è Parameters:\")\n",
    "print(f\"   - n_estimators: {final_model.n_estimators}\")\n",
    "print(f\"   - max_depth: {final_model.max_depth}\")\n",
    "print(f\"   - min_samples_split: {final_model.min_samples_split}\")\n",
    "print(f\"   - min_samples_leaf: {final_model.min_samples_leaf}\")\n",
    "\n",
    "print(\"\\nüöÄ Training final model...\")\n",
    "final_model.fit(X_train_scaled, y_train)\n",
    "print(\"‚úÖ Training completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7686e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " PERFORMANCE METRICS:\n",
      "   Train Accuracy:      1.0000 (100.00%)\n",
      "   Test Accuracy:       1.0000 (100.00%)\n",
      "   CV Score (mean):     1.0000 ¬± 0.0000\n",
      "   Overfitting:         0.0000\n"
     ]
    }
   ],
   "source": [
    "# 7. MODEL DEƒûERLENDƒ∞RMESƒ∞\n",
    "\n",
    "# Tahminler(Predictions):\n",
    "\n",
    "y_train_pred = final_model.predict(X_train_scaled)\n",
    "y_test_pred = final_model.predict(X_test_scaled)\n",
    "\n",
    "# Doƒüruluk puanlarƒ±(Accuracy scores):\n",
    "\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Cross-validation\n",
    "CV_FOLDS = 5  # 5 katlƒ± √ßapraz doƒürulama (5-fold cross-validation)\n",
    "cv_scores = cross_val_score(\n",
    "    final_model, X_train_scaled, y_train, \n",
    "    cv=CV_FOLDS, scoring='accuracy')\n",
    "\n",
    "print(f\"\\n PERFORMANCE METRICS:\")\n",
    "print(f\"   Train Accuracy:      {train_acc:.4f} ({train_acc*100:.2f}%)\")\n",
    "print(f\"   Test Accuracy:       {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "print(f\"   CV Score (mean):     {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}\")\n",
    "print(f\"   Overfitting:         {(train_acc - test_acc):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59a3ebb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CLASSIFICATION REPORT:\n",
      "================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       1.00      1.00      1.00        73\n",
      "         Low       1.00      1.00      1.00        61\n",
      "      Medium       1.00      1.00      1.00        66\n",
      "\n",
      "    accuracy                           1.00       200\n",
      "   macro avg       1.00      1.00      1.00       200\n",
      "weighted avg       1.00      1.00      1.00       200\n",
      "\n",
      "\n",
      " CONFUSION MATRIX:\n",
      "================================================================================\n",
      "              Pred: Low  Pred: Medium  Pred: High\n",
      "True: Low            61             0           0\n",
      "True: Medium          0            66           0\n",
      "True: High            0             0          73\n",
      "\n",
      " PER-CLASS ACCURACY:\n",
      "   Low       : 1.0000 (100.00%)\n",
      "   Medium    : 1.0000 (100.00%)\n",
      "   High      : 1.0000 (100.00%)\n"
     ]
    }
   ],
   "source": [
    "# Detailed classification report\n",
    "print(f\"\\n CLASSIFICATION REPORT:\")\n",
    "print(\"=\"*80)\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "print(f\"\\n CONFUSION MATRIX:\")\n",
    "print(\"=\"*80)\n",
    "cm = confusion_matrix(y_test, y_test_pred, labels=['Low', 'Medium', 'High'])\n",
    "cm_df = pd.DataFrame(\n",
    "    cm,\n",
    "    index=['True: Low', 'True: Medium', 'True: High'],\n",
    "    columns=['Pred: Low', 'Pred: Medium', 'Pred: High']\n",
    ")\n",
    "print(cm_df)\n",
    "\n",
    "# Per-class accuracy\n",
    "print(f\"\\n PER-CLASS ACCURACY:\")\n",
    "for i, label in enumerate(['Low', 'Medium', 'High']):\n",
    "    class_acc = cm[i, i] / cm[i, :].sum()\n",
    "    print(f\"   {label:10s}: {class_acc:.4f} ({class_acc*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81f1c83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Top 10 Most Important Features:\n",
      "               feature  importance\n",
      "      Symptom_Severity    0.212949\n",
      "        Passive Smoker    0.095341\n",
      "    Overall_Risk_Score    0.092324\n",
      "               Obesity    0.087199\n",
      "     Coughing of Blood    0.085572\n",
      "              Wheezing    0.047258\n",
      "        Lifestyle_Risk    0.040275\n",
      "               Fatigue    0.038828\n",
      "Critical_Symptom_Count    0.037338\n",
      "     Respiratory_Score    0.029238\n"
     ]
    }
   ],
   "source": [
    "# 8. √ñZELLƒ∞K √ñNEMƒ∞ (SON MODEL)\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': FINAL_FEATURES,\n",
    "    'importance': final_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\n Top 10 Most Important Features:\")\n",
    "print(importance_df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb7b3752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model saved: final_model.pkl\n",
      "‚úÖ Scaler saved: final_scaler.pkl\n",
      "‚úÖ Feature list saved: final_features.txt\n",
      "‚úÖ Metadata saved: pipeline_metadata.txt\n"
     ]
    }
   ],
   "source": [
    "# 9. MODEL KALICILIƒûI\n",
    "\n",
    "# Modeli kaydedelim.\n",
    "with open('final_model.pkl', 'wb') as f:\n",
    "    pickle.dump(final_model, f)\n",
    "print(\"‚úÖ Model saved: final_model.pkl\")\n",
    "\n",
    "# √ñl√ßekleyiciyi kaydedelim.\n",
    "with open('final_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(\"‚úÖ Scaler saved: final_scaler.pkl\")\n",
    "\n",
    "# √ñzellik listesini kaydet\n",
    "with open('final_features.txt', 'w') as f:\n",
    "    f.write(\"FINAL FEATURE SET\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    for i, feat in enumerate(FINAL_FEATURES, 1):\n",
    "        f.write(f\"{i}. {feat}\\n\")\n",
    "print(\"‚úÖ Feature list saved: final_features.txt\")\n",
    "\n",
    "# Pipeline meta verilerini kaydedelim.\n",
    "metadata = {\n",
    "    'model_type': final_model.__class__.__name__,\n",
    "    'n_features': len(FINAL_FEATURES),\n",
    "    'train_size': len(X_train),\n",
    "    'test_size': len(X_test),\n",
    "    'test_accuracy': test_acc,\n",
    "    'cv_score_mean': cv_scores.mean(),\n",
    "    'cv_score_std': cv_scores.std(),\n",
    "    'random_state': RANDOM_STATE,\n",
    "    'date_trained': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "}\n",
    "\n",
    "with open('pipeline_metadata.txt', 'w') as f:\n",
    "    f.write(\"FINAL PIPELINE METADATA\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    for key, value in metadata.items():\n",
    "        f.write(f\"{key}: {value}\\n\")\n",
    "print(\"‚úÖ Metadata saved: pipeline_metadata.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d43f0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ PIPELINE SUCCESSFULLY BUILT!\n",
      "\n",
      "MODEL INFORMATION:\n",
      "Model Type:          RandomForestClassifier\n",
      "Number of Features:  28\n",
      "Training Samples:    800\n",
      "Test Samples:        200\n",
      "\n",
      "üìà PERFORMANCE METRICS:\n",
      "Test Accuracy:       1.0000 (100.00%)\n",
      "CV Score:            1.0000 ¬± 0.0000\n",
      "Overfitting:         0.0000\n",
      "\n",
      "üì¶ SAVED ARTIFACTS:\n",
      "‚úÖ final_model.pkl\n",
      "‚úÖ final_scaler.pkl\n",
      "‚úÖ final_features.txt\n",
      "‚úÖ pipeline_metadata.txt\n",
      "\n",
      "üöÄ READY FOR DEPLOYMENT:\n",
      "The model is ready to be integrated into inference pipeline.\n",
      "Use inference.py to make predictions on new data.\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "PIPELINE BUILD COMPLETED! üéâ\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 10. SON √ñZET\n",
    "\n",
    "print(f\"\"\"\n",
    "‚úÖ PIPELINE SUCCESSFULLY BUILT!\n",
    "\n",
    "MODEL INFORMATION:\n",
    "Model Type:          {final_model.__class__.__name__}\n",
    "Number of Features:  {len(FINAL_FEATURES)}\n",
    "Training Samples:    {len(X_train):,}\n",
    "Test Samples:        {len(X_test):,}\n",
    "\n",
    "üìà PERFORMANCE METRICS:\n",
    "Test Accuracy:       {test_acc:.4f} ({test_acc*100:.2f}%)\n",
    "CV Score:            {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}\n",
    "Overfitting:         {(train_acc - test_acc):.4f}\n",
    "\n",
    "üì¶ SAVED ARTIFACTS:\n",
    "‚úÖ final_model.pkl\n",
    "‚úÖ final_scaler.pkl\n",
    "‚úÖ final_features.txt\n",
    "‚úÖ pipeline_metadata.txt\n",
    "\n",
    "üöÄ READY FOR DEPLOYMENT:\n",
    "The model is ready to be integrated into inference pipeline.\n",
    "Use inference.py to make predictions on new data.\n",
    "\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PIPELINE BUILD COMPLETED! üéâ\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc80991",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
