{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06800890",
   "metadata": {},
   "source": [
    "04- Model Optimization - Cancer Risk Prediction\n",
    "============================================\n",
    "Farklƒ± modeller ve hyperparameter tuning ile en iyi performansƒ± elde etmek amacƒ±yla test edilecektir.\n",
    "\n",
    "Test edilecek modeller:\n",
    "1. Logistic Regression (Baseline)\n",
    "2. Random Forest\n",
    "3. XGBoost\n",
    "4. LightGBM\n",
    "5. Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "843096d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "196c5f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineered data loaded!\n",
      "Data Shape: (1000, 44)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv('../data/processed/cancer_data_feature_engineered.csv')\n",
    "    print(\"Feature engineered data loaded!\")\n",
    "except:\n",
    "    df = pd.read_csv('..data/raw/cancer-patient-data-sets.csv')\n",
    "    print(\"Using original data (feature engineered data not found!)\")\n",
    "\n",
    "print(f\"Data Shape: {df.shape}\")\n",
    "\n",
    "# Bu yapƒ±, √∂zellikle b√ºy√ºk ML projelerinde \"eƒüer bir √∂nceki adƒ±mƒ±n √ßƒ±ktƒ±sƒ± yoksa, en azƒ±ndan ham veriyle \n",
    "# dene\" mantƒ±ƒüƒ±nƒ± uygulayarak kodun direncini ve yeniden √ºretilebilirliƒüini artƒ±rƒ±r.\n",
    "# Verilerin bu ≈üekilde y√ºklenmesi model performansƒ±nƒ± optimize etmekten ziyade, ML pipeline'nƒ±n saƒülƒ±ƒüƒ±nƒ± ve profesyonelliƒüini optimize eder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5846d82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Count: 41\n",
      "Class Distribution:\n",
      "Level\n",
      "High      365\n",
      "Medium    332\n",
      "Low       303\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "feature_cols = [col for col in df.columns if col not in ['index', 'Patient Id', 'Level']]\n",
    "X = df[feature_cols]\n",
    "y = df['Level']\n",
    "\n",
    "print(f\"Feature Count: {len(feature_cols)}\")\n",
    "print(f\"Class Distribution:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "#  Veriler √∂zellik sayƒ±sƒ± ve target deƒüi≈üken belirlenecek ≈üekilde ayarlandƒ± ve bakƒ±lmayacak s√ºtunlar silindi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b57f8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test verileri olarak ayrƒ±ldƒ±.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49092d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train: 800, Test: 200\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nTrain: {X_train.shape[0]}, Test: {X_test.shape[0]}\")\n",
    "\n",
    "# Veriler scale(√∂l√ßeklendirme) edildi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86b8b299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Hyperparameter Tuning with GridSearchCV...\n",
      "Best Parameters: {'C': 0.1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Train Accuracy: 1.0000\n",
      "Test Accuracy:  1.0000\n",
      "CV Score:       1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  MODEL 1: LOGISTIC REGRESSION\n",
    "\n",
    "lr_params = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs'],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "print(\"üîß Hyperparameter Tuning with GridSearchCV...\")\n",
    "lr_grid = GridSearchCV(\n",
    "    LogisticRegression(random_state=42),\n",
    "    lr_params,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "lr_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "lr_best = lr_grid.best_estimator_\n",
    "lr_train_score = lr_best.score(X_train_scaled, y_train)\n",
    "lr_test_score = lr_best.score(X_test_scaled, y_test)\n",
    "lr_cv_score = cross_val_score(lr_best, X_train_scaled, y_train, cv=5).mean()\n",
    "\n",
    "print(f\"Best Parameters: {lr_grid.best_params_}\")\n",
    "print(f\"Train Accuracy: {lr_train_score:.4f}\")\n",
    "print(f\"Test Accuracy:  {lr_test_score:.4f}\")\n",
    "print(f\"CV Score:       {lr_cv_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45a92b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL 2: RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a55ca34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Hyperparameter Tuning with GridSearchCV...\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Train Accuracy: 1.0000\n",
      "Test Accuracy:  1.0000\n",
      "CV Score:       1.0000\n"
     ]
    }
   ],
   "source": [
    "rf_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 15, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "print(\"üîß Hyperparameter Tuning with GridSearchCV...\")\n",
    "rf_grid = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    rf_params,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "rf_grid.fit(X_train, y_train)  # RF doesn't require scaling\n",
    "\n",
    "rf_best = rf_grid.best_estimator_\n",
    "rf_train_score = rf_best.score(X_train, y_train)\n",
    "rf_test_score = rf_best.score(X_test, y_test)\n",
    "rf_cv_score = cross_val_score(rf_best, X_train, y_train, cv=5).mean()\n",
    "\n",
    "print(f\"Best Parameters: {rf_grid.best_params_}\")\n",
    "print(f\"Train Accuracy: {rf_train_score:.4f}\")\n",
    "print(f\"Test Accuracy:  {rf_test_score:.4f}\")\n",
    "print(f\"CV Score:       {rf_cv_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a001670e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Hyperparameter Tuning with GridSearchCV...\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      " Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8}\n",
      " Train Accuracy: 1.0000\n",
      " Test Accuracy:  1.0000\n",
      " CV Score:       1.0000\n"
     ]
    }
   ],
   "source": [
    "# MODEL 3: XGBOOST\n",
    "\n",
    "# Encode target for XGBoost\n",
    "y_train_encoded = y_train.map({'Low': 0, 'Medium': 1, 'High': 2})\n",
    "y_test_encoded = y_test.map({'Low': 0, 'Medium': 1, 'High': 2})\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "print(\"üîß Hyperparameter Tuning with GridSearchCV...\")\n",
    "xgb_grid = GridSearchCV(\n",
    "    xgb.XGBClassifier(random_state=42, eval_metric='mlogloss'),\n",
    "    xgb_params,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "xgb_grid.fit(X_train_scaled, y_train_encoded)\n",
    "\n",
    "xgb_best = xgb_grid.best_estimator_\n",
    "xgb_train_score = xgb_best.score(X_train_scaled, y_train_encoded)\n",
    "xgb_test_score = xgb_best.score(X_test_scaled, y_test_encoded)\n",
    "xgb_cv_score = cross_val_score(xgb_best, X_train_scaled, y_train_encoded, cv=5).mean()\n",
    "\n",
    "print(f\" Best Parameters: {xgb_grid.best_params_}\")\n",
    "print(f\" Train Accuracy: {xgb_train_score:.4f}\")\n",
    "print(f\" Test Accuracy:  {xgb_test_score:.4f}\")\n",
    "print(f\" CV Score:       {xgb_cv_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c81edee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Hyperparameter Tuning with GridSearchCV...\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200, 'num_leaves': 31}\n",
      "Train Accuracy: 1.0000\n",
      "Test Accuracy:  1.0000\n",
      "CV Score:       1.0000\n"
     ]
    }
   ],
   "source": [
    "# MODEL 4: LIGHTGBM\n",
    "\n",
    "lgb_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7, -1],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'num_leaves': [31, 50, 70]\n",
    "}\n",
    "\n",
    "print(\"üîß Hyperparameter Tuning with GridSearchCV...\")\n",
    "lgb_grid = GridSearchCV(\n",
    "    lgb.LGBMClassifier(random_state=42, verbose=-1),\n",
    "    lgb_params,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "lgb_grid.fit(X_train_scaled, y_train_encoded)\n",
    "\n",
    "lgb_best = lgb_grid.best_estimator_\n",
    "lgb_train_score = lgb_best.score(X_train_scaled, y_train_encoded)\n",
    "lgb_test_score = lgb_best.score(X_test_scaled, y_test_encoded)\n",
    "lgb_cv_score = cross_val_score(lgb_best, X_train_scaled, y_train_encoded, cv=5).mean()\n",
    "\n",
    "print(f\"Best Parameters: {lgb_grid.best_params_}\")\n",
    "print(f\"Train Accuracy: {lgb_train_score:.4f}\")\n",
    "print(f\"Test Accuracy:  {lgb_test_score:.4f}\")\n",
    "print(f\"CV Score:       {lgb_cv_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9968bdd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Hyperparameter Tuning with GridSearchCV...\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      " Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8}\n",
      " Train Accuracy: 1.0000\n",
      " Test Accuracy:  1.0000\n",
      " CV Score:       1.0000\n"
     ]
    }
   ],
   "source": [
    "# MODEL 5: GRADIENT BOOSTING\n",
    "\n",
    "gb_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "print(\"üîß Hyperparameter Tuning with GridSearchCV...\")\n",
    "gb_grid = GridSearchCV(\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    gb_params,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "gb_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "gb_best = gb_grid.best_estimator_\n",
    "gb_train_score = gb_best.score(X_train_scaled, y_train)\n",
    "gb_test_score = gb_best.score(X_test_scaled, y_test)\n",
    "gb_cv_score = cross_val_score(gb_best, X_train_scaled, y_train, cv=5).mean()\n",
    "\n",
    "print(f\" Best Parameters: {gb_grid.best_params_}\")\n",
    "print(f\" Train Accuracy: {gb_train_score:.4f}\")\n",
    "print(f\" Test Accuracy:  {gb_test_score:.4f}\")\n",
    "print(f\" CV Score:       {gb_cv_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df16208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              Model  Train_Accuracy  Test_Accuracy  CV_Score  Overfitting\n",
      "Logistic Regression             1.0            1.0       1.0          0.0\n",
      "      Random Forest             1.0            1.0       1.0          0.0\n",
      "            XGBoost             1.0            1.0       1.0          0.0\n",
      "           LightGBM             1.0            1.0       1.0          0.0\n",
      "  Gradient Boosting             1.0            1.0       1.0          0.0\n",
      "\n",
      "üèÜ BEST MODEL: Logistic Regression\n",
      "   Test Accuracy: 1.0000\n",
      "   CV Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# 7. MODEL COMPARISON\n",
    "#  Modeller arasƒ±nda kƒ±yaslama yapƒ±ldƒ±.\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'XGBoost', 'LightGBM', 'Gradient Boosting'],\n",
    "    'Train_Accuracy': [lr_train_score, rf_train_score, xgb_train_score, lgb_train_score, gb_train_score],\n",
    "    'Test_Accuracy': [lr_test_score, rf_test_score, xgb_test_score, lgb_test_score, gb_test_score],\n",
    "    'CV_Score': [lr_cv_score, rf_cv_score, xgb_cv_score, lgb_cv_score, gb_cv_score]\n",
    "})\n",
    "\n",
    "results['Overfitting'] = results['Train_Accuracy'] - results['Test_Accuracy']\n",
    "results = results.sort_values('Test_Accuracy', ascending=False)\n",
    "\n",
    "print(\"\\n\" + results.to_string(index=False))\n",
    "\n",
    "# Best model\n",
    "best_model_name = results.iloc[0]['Model']\n",
    "best_model_test_acc = results.iloc[0]['Test_Accuracy']\n",
    "best_model_cv = results.iloc[0]['CV_Score']\n",
    "\n",
    "print(f\"\\n BEST MODEL: {best_model_name}\")\n",
    "print(f\"   Test Accuracy: {best_model_test_acc:.4f}\")\n",
    "print(f\"   CV Score: {best_model_cv:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ac086d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       1.00      1.00      1.00        73\n",
      "         Low       1.00      1.00      1.00        61\n",
      "      Medium       1.00      1.00      1.00        66\n",
      "\n",
      "    accuracy                           1.00       200\n",
      "   macro avg       1.00      1.00      1.00       200\n",
      "weighted avg       1.00      1.00      1.00       200\n",
      "\n",
      "\n",
      " Confusion Matrix:\n",
      "              Pred: Low  Pred: Medium  Pred: High\n",
      "True: Low            61             0           0\n",
      "True: Medium          0            66           0\n",
      "True: High            0             0          73\n"
     ]
    }
   ],
   "source": [
    "# DETAILED REPORT FOR BEST MODEL\n",
    "# En iyi model i√ßin detaylƒ± bir rapor yazƒ±ldƒ±.\n",
    "\n",
    "# Get best model predictions\n",
    "if best_model_name == 'Logistic Regression':\n",
    "    best_model = lr_best\n",
    "    y_pred = best_model.predict(X_test_scaled)\n",
    "elif best_model_name == 'Random Forest':\n",
    "    best_model = rf_best\n",
    "    y_pred = best_model.predict(X_test)\n",
    "elif best_model_name == 'XGBoost':\n",
    "    best_model = xgb_best\n",
    "    y_pred_encoded = best_model.predict(X_test_scaled)\n",
    "    y_pred = pd.Series(y_pred_encoded).map({0: 'Low', 1: 'Medium', 2: 'High'})\n",
    "elif best_model_name == 'LightGBM':\n",
    "    best_model = lgb_best\n",
    "    y_pred_encoded = best_model.predict(X_test_scaled)\n",
    "    y_pred = pd.Series(y_pred_encoded).map({0: 'Low', 1: 'Medium', 2: 'High'})\n",
    "else:  # Gradient Boosting\n",
    "    best_model = gb_best\n",
    "    y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\n Confusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred, labels=['Low', 'Medium', 'High'])\n",
    "cm_df = pd.DataFrame(\n",
    "    cm,\n",
    "    index=['True: Low', 'True: Medium', 'True: High'],\n",
    "    columns=['Pred: Low', 'Pred: Medium', 'Pred: High']\n",
    ")\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a391be45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model comparison saved: model_comparison_results.csv\n",
      " Best model saved: best_model.pkl (Logistic Regression)\n",
      " Scaler saved: scaler.pkl\n",
      "\n",
      "================================================================================\n",
      "MODEL OPTIMIZATION COMPLETED! \n",
      "================================================================================\n",
      "\n",
      " Winner: Logistic Regression with 1.0000 test accuracy\n"
     ]
    }
   ],
   "source": [
    "# Save comparison results\n",
    "results.to_csv('model_comparison_results.csv', index=False)\n",
    "print(\" Model comparison saved: model_comparison_results.csv\")\n",
    "\n",
    "# Save best model (using pickle or joblib)\n",
    "import pickle\n",
    "\n",
    "with open('best_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "print(f\" Best model saved: best_model.pkl ({best_model_name})\")\n",
    "\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(\" Scaler saved: scaler.pkl\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL OPTIMIZATION COMPLETED! \")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n Winner: {best_model_name} with {best_model_test_acc:.4f} test accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
